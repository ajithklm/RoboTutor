{
  "name": "Automatic Hand Raising Gesture Detection in an Image for a Nao Robot",
  "tagline": "Research Internship at TU Delft Robotics Institute 2016",
  "body": "#INTRODUCTION\r\nThese are the works that I did during my research internship project in the [RoboTutor](https://robotutor.weblog.tudelft.nl/) team of [TU Delft Robotics Institute](http://robotics.tudelft.nl/). The main goal is to detect hand-raising gestures in a video, and feed the coordinates of such gesture to the Nao Robot central processor. In the process, I tried out different methods as listed below:     \r\n   \r\n### (1) Running Faster R-CNN algorithm in Caffe ([demo_robotutor.py](https://github.com/edwardelson/RoboTutor/blob/master/demo_robotutor.py))   \r\nDuring this period, Deep CNN was one of the state-of-the-art and the \"hottest\" method in the community. So we initially thought, why don't we try to adapt it for hand-raising gesture detection. So we forked [Ross Girshick's Faster R-CNN repo](https://github.com/rbgirshick/py-faster-rcnn) and modify it so that it can run on video (initially it was only for image). After spending some time installing Caffe in my Ubuntu laptop, it runs quite well. However, as I can't use the GPU in my laptop (not enough memory), we installed a new computer in the [INSYGHT lab](http://www.insyghtlab.tudelft.nl/) with GeForce GTX 680 GPU. The result can be seen in the following image.\r\n  \r\n[Resulting Image demo Faster R-CNN]   \r\n  \r\n### (2) Transfer Learning to train a Pre-existing Deep CNN for self-crafted hand-raising images ([robonet.py](https://github.com/edwardelson/RoboTutor/blob/master/haar_handraise_detection.py))    \r\nThe next step is to train Faster R-CNN for a new dataset of handraising gestures that it has not seen before. Faster R-CNN consists of several stages: Region Proposal Network, Convolutional Layers and Classification Network. In this step, we focused more on the Convolutional Layers and Classification Network. We figured out that these layers were actually a result of transfer learning from another existing deep networks. So we went to [Caffe Model Zoo](https://github.com/BVLC/caffe/wiki/Model-Zoo), and browse for some existing pretrained networks. As a preliminary test, we chose the [Flickr model](http://caffe.berkeleyvision.org/gathered/examples/finetune_flickr_style.html) as there's an existing tutorial from Caffe on how to dissect and retrain it.  \r\n  \r\nAnother problem is that there's no existing dataset on hand-raising gesture images. So we decided to try crafting our own dataset from scratch. We experimented with very small size of dataset (about the size of 20 images). We then train the network for this dataset.\r\n  \r\nThe result is of course very fast convergence, with 100% training data accuracy. This is absolutely an overfit, and when tested with a new image it has never seen, it performs almost no better than chance. We are left with the option of enlarging the dataset (which takes a lot of time) or try out another method. \r\n\r\n[training result in Ubuntu]  \r\n\r\n### (3) Haar Feature Approach for Face + Hand Detection ([haar_handraise_detection.py](https://github.com/edwardelson/RoboTutor/blob/master/robonet.py))\r\nWe were inspired by a paper which tries to tackle this problem by detecting face and hand separately. We borrowed this idea and decide to find the Euclidean distance between detected faces and hands to decide whether a hand-raising gesture exists. We experimented with Haar Feature with Skin Detection. The result can be seen below.\r\n  \r\n[image of Skin Detection + Handraising]  \r\n  \r\nWe wanted to use the same idea, but now using Faster R-CNN to train and detect face and hand, hence combining step 1-3. However, we did not have enough time as my Student Exchange Period is ending soon. So we stopped at this stage and proceed to implement the Java wrapper for the code. This is to allow the Nao robot to use this module.\r\n\r\n### (4) Implementing Java Wrapper for Python code to fit into the Nao system (to be updated)    \r\nThis work is under progress.  \r\n     \r\n>[Back to List of Projects](https://edwardelson.github.io)  ",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}